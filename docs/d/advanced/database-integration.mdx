---
title: Database Integration
---

Nanoservice-ts applications frequently need to interact with databases to store, retrieve, and manage data. Nodes provide the ideal encapsulation for database operations, allowing you to create reusable components for common database tasks.

This guide covers patterns and best practices for integrating databases within your Nanoservice-ts Nodes, using examples like PostgreSQL and MongoDB.

## General Approach

The core idea is to have specific Nodes responsible for database interactions. These Nodes will typically:

1.  **Establish a Connection:** Manage database connections, ideally using connection pooling for efficiency.
2.  **Execute Queries/Operations:** Perform CRUD (Create, Read, Update, Delete) operations or other database-specific commands.
3.  **Handle Inputs/Outputs:** Accept parameters for queries (e.g., IDs, data payloads) and return results or status.
4.  **Manage Errors:** Gracefully handle database connection errors, query failures, or data-related issues.

Configuration for database connections (host, port, user, password, database name) should always be managed via environment variables (see [Configuration](./../fundamentals/configuration.mdx)).

## Example: PostgreSQL Integration

Nanoservice-ts can integrate with PostgreSQL using popular Node.js libraries like `pg` (node-postgres).

Let's consider a conceptual `postgres-query-node` (similar to the example provided in the Nanoservice-ts starter).

**Node Structure (`src/nodes/postgres-query-node/index.ts`):**

```typescript
import { type INanoServiceResponse, NanoService, NanoServiceResponse } from "@nanoservice-ts/runner";
import { type Context, GlobalError } from "@nanoservice-ts/shared";
import { Pool, QueryResult } from 'pg'; // Using node-postgres

// Connection Pool - should be initialized once, ideally outside the handle method
// or managed carefully to avoid creating too many connections.
// For a real application, this might be part of a shared DB utility or initialized at app startup.
let pool: Pool;

const getPool = () => {
  if (!pool) {
    pool = new Pool({
      user: process.env.DB_USER,
      host: process.env.DB_HOST,
      database: process.env.DB_NAME,
      password: process.env.DB_PASSWORD,
      port: parseInt(process.env.DB_PORT || "5432"),
      // ssl: process.env.DB_SSL === 'true' ? { rejectUnauthorized: false } : undefined,
      // connectionTimeoutMillis: 2000,
      // idleTimeoutMillis: 10000,
      // max: 20, // Max number of clients in the pool
    });

    pool.on('error', (err, client) => {
      console.error('Unexpected error on idle client', err); // Use ctx.logger in a real node if possible
      // process.exit(-1); // Or handle more gracefully
    });
  }
  return pool;
};


type InputType = {
  query: string; // SQL query string
  values?: any[]; // Optional array of parameters for prepared statements
};

type OutputType = {
  rowCount: number | null;
  rows: any[];
  command: string;
  // Potentially more fields from QueryResult
};

export default class PostgresQueryNode extends NanoService<InputType> {
  constructor() {
    super();
    this.inputSchema = {
      type: "object",
      properties: {
        query: { type: "string" },
        values: { type: "array", items: { type: "any" } }
      },
      required: ["query"]
    };
    this.outputSchema = { /* Define based on OutputType */ };
    // Initialize the pool when the node is constructed or on first use
    getPool(); 
  }

  async handle(ctx: Context, inputs: InputType): Promise<INanoServiceResponse> {
    const response: NanoServiceResponse = new NanoServiceResponse();
    const currentPool = getPool();
    let client;

    try {
      ctx.logger.info("Executing PostgreSQL query", { query: inputs.query, values: inputs.values });
      client = await currentPool.connect();
      const result: QueryResult = await client.query(inputs.query, inputs.values);
      
      const output: OutputType = {
        rowCount: result.rowCount,
        rows: result.rows,
        command: result.command,
      };
      response.setSuccess(output);
      ctx.logger.debug("PostgreSQL query executed successfully", { rowCount: result.rowCount });

    } catch (error: unknown) {
      const err = error as Error;
      ctx.logger.error("Error executing PostgreSQL query", { error: err.message, stack: err.stack });
      response.setError(new GlobalError(err.message, 500));
    } finally {
      if (client) {
        client.release(); // Always release the client back to the pool
      }
    }
    return response;
  }
}
```

**Workflow Usage:**

```json
// In a workflow JSON file
{
  // ... name, trigger ...
  "steps": [
    {
      "name": "get-user-by-id",
      "node": "postgres-query-node", // Assuming registered with this name
      "type": "module"
    }
  ],
  "nodes": {
    "get-user-by-id": {
      "inputs": {
        "query": "SELECT * FROM users WHERE id = $1",
        "values": ["{{trigger.params.userId}}"] // Example: getting userId from HTTP trigger
      }
    }
  }
}
```

### Key Considerations for PostgreSQL:

1.  **Connection Pooling:** Use a connection pool (`pg.Pool`) to efficiently manage database connections. Initialize the pool once and reuse it.
2.  **Parameterized Queries (Prepared Statements):** Always use parameterized queries (passing values as an array in `client.query(sql, values)`) to prevent SQL injection vulnerabilities.
3.  **Client Release:** Ensure that acquired clients are always released back to the pool using `client.release()` in a `finally` block.
4.  **Transaction Management:** For operations requiring multiple queries to be atomic, you'll need to manage transactions (`BEGIN`, `COMMIT`, `ROLLBACK`) explicitly. This might involve a more specialized node or multiple steps in a workflow.

## Example: MongoDB Integration

For MongoDB, you would typically use the official MongoDB Node.js driver.

**Conceptual `mongodb-operation-node`:**

```typescript
import { type INanoServiceResponse, NanoService, NanoServiceResponse } from "@nanoservice-ts/runner";
import { type Context, GlobalError } from "@nanoservice-ts/shared";
import { MongoClient, Db, Collection, ObjectId } from 'mongodb';

let client: MongoClient;
let db: Db;

const connectDB = async (ctx: Context) => {
  if (client && client.isConnected()) {
    return;
  }
  try {
    const uri = process.env.MONGODB_URI || "mongodb://localhost:27017";
    const dbName = process.env.MONGODB_DB_NAME || "mydatabase";
    client = new MongoClient(uri, { useUnifiedTopology: true });
    await client.connect();
    db = client.db(dbName);
    ctx.logger.info("Successfully connected to MongoDB");
  } catch (error) {
    ctx.logger.error("Failed to connect to MongoDB", { error });
    throw error; // Propagate error to be caught by handle method
  }
};

// Example Input: could be more specific based on operation
type InputType = {
  collection: string;
  operation: 'findOne' | 'insertOne' | 'updateOne' | 'deleteOne';
  query?: any;
  document?: any;
  update?: any;
  options?: any;
};

export default class MongoDBOperationNode extends NanoService<InputType> {
  constructor() {
    super();
    // Define input/output schemas based on InputType and expected results
  }

  async handle(ctx: Context, inputs: InputType): Promise<INanoServiceResponse> {
    const response: NanoServiceResponse = new NanoServiceResponse();
    try {
      await connectDB(ctx); // Ensure connection
      const collection: Collection = db.collection(inputs.collection);
      let result: any;

      ctx.logger.info(`Performing MongoDB operation: ${inputs.operation} on collection ${inputs.collection}`);

      switch (inputs.operation) {
        case 'findOne':
          result = await collection.findOne(inputs.query || {}, inputs.options || {});
          break;
        case 'insertOne':
          result = await collection.insertOne(inputs.document || {}, inputs.options || {});
          break;
        // Add cases for updateOne, deleteOne, find, etc.
        default:
          throw new Error(`Unsupported MongoDB operation: ${inputs.operation}`);
      }
      response.setSuccess(result);
      ctx.logger.debug("MongoDB operation successful", { result });

    } catch (error: unknown) {
      const err = error as Error;
      ctx.logger.error("Error performing MongoDB operation", { error: err.message });
      response.setError(new GlobalError(err.message, 500));
    }
    // Note: MongoClient typically manages its own connection pool.
    // Closing the client might be done at application shutdown, not per-node execution.
    return response;
  }
}
```

### Key Considerations for MongoDB:

1.  **Connection Management:** The MongoDB driver manages connection pooling internally. Typically, you connect once when your application starts (or on first use by a node) and reuse the `Db` instance.
2.  **Operations:** Use the appropriate methods on the `Collection` object (`findOne`, `insertOne`, `updateOne`, `deleteOne`, `find`, etc.).
3.  **ObjectIDs:** When querying by `_id`, ensure you are using MongoDB `ObjectId` instances if your IDs are stored as such.
4.  **Schema Validation:** While MongoDB is schema-less, your application should enforce a schema, often at the Node input/output level or using Mongoose/TypeORM if you prefer an ODM/ORM.

## Best Practices for Database Nodes

1.  **Single Responsibility:** Design nodes to perform specific database operations (e.g., `get-user-by-id-node`, `create-order-node`) rather than generic query execution nodes, unless a generic query node is explicitly what you need (like the `postgres-query-node` example).
2.  **Secure Configuration:** Store database credentials securely using environment variables.
3.  **Connection Management:** Use connection pooling and ensure connections/clients are properly released.
4.  **Error Handling:** Implement robust error handling for connection issues, query failures, and data validation problems.
5.  **Input Validation & Sanitization:** Validate and sanitize all inputs used in database queries to prevent injection attacks (parameterized queries are key for SQL).
6.  **Abstraction:** Consider creating a shared database utility or service within your `src/common/` or `src/services/` directory if multiple nodes need to interact with the same database. This utility can handle connection management and provide helper functions for common queries.
7.  **Testing:** Write unit tests for your database nodes, potentially mocking the database client or using an in-memory test database.

By following these patterns, you can create robust and reusable Nanoservice-ts Nodes for all your database interaction needs.
